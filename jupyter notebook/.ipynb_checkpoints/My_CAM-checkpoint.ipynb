{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pdb\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = torch.nn.Linear(num_ftrs, 257) # Modify the layer\n",
    "\n",
    "finalconv_name = 'layer4'\n",
    "model_ft.eval()\n",
    "\n",
    "model_ft.load_state_dict(torch.load(\"test_model.pth\",map_location='cpu')) # use my model parameter and use cpu\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((224,224)),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n",
    "\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "model_ft._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
    "\n",
    "# get the softmax weight\n",
    "params = list(model_ft.parameters())\n",
    "weight_softmax = np.squeeze(params[-2].data.numpy())\n",
    "\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pil = Image.open(\"datasets/caltech-256-image-dataset/256_ObjectCategories/212.teapot/212_0136.jpg\") # you can change image at here\n",
    "img_pil.save('temp.jpg') # I do this for convenience.\n",
    "\n",
    "img_tensor = preprocess(img_pil)\n",
    "img_variable = Variable(img_tensor.unsqueeze(0))\n",
    "logit = model_ft(img_variable)\n",
    "\n",
    "DATA_DIR = \"datasets/caltech-256-image-dataset/256_ObjectCategories\"\n",
    "listDir = os.listdir(DATA_DIR)[1:]\n",
    "listCategories = []\n",
    "for i in listDir:\n",
    "    listCategories.append(i[4:])\n",
    "classes = {key:value for (key, value) in enumerate(listCategories)}\n",
    "\n",
    "h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "probs = probs.numpy()\n",
    "idx = idx.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 -> teapot\n",
      "0.000 -> fire-hydrant\n",
      "0.000 -> buddha-101\n",
      "0.000 -> beer-mug\n",
      "0.000 -> ewer-101\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output CAM.jpg for the top1 prediction: teapot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])\n",
    "\n",
    "# render the CAM and output\n",
    "print('output CAM.jpg for the top1 prediction: %s'%classes[idx[0]])\n",
    "img = cv2.imread('test2.jpg')\n",
    "height, width, _ = img.shape\n",
    "heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.3 + img * 0.5\n",
    "cv2.imwrite('CAM.jpg', result) # save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check result by opencv \n",
    "image1 = cv2.imread('temp.jpg')\n",
    "image2 = cv2.imread('CAM.jpg')\n",
    "concat_image = np.hstack((image1,image2))\n",
    "cv2.imshow('result',concat_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
